from string import ascii_lowercase, digitsfrom application.rests.azure_translator import adetect, atranslatefrom application.rests.google_translator import gdetect, gtranslatedef clean_text(text: str):    accepted_chars = ascii_lowercase + digits + "_ " + " " + "ğüşöçĞÜİŞÖÇ"    s1 = " ".join(text.split())    s2 = "".join([c for c in s1 if c in accepted_chars])    return s2def tokenize(s):    return [w.strip() for w in s.split()]def lang_detect_offline(text):    try:        from application.app import lang_model        return lang_model.predict(text)[0][0].split("__")[-1]    except Exception:        return "en"def lang_detect(text):    return adetect(text) or gdetect(text) or lang_detect_offline(text)def translate(text, dest_lang):    return atranslate(text, dest_lang) or gtranslate(text, dest_lang)